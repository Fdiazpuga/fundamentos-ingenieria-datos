{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Clase M3 AE1-1 – Explorando matrices y operaciones básicas\n",
        "\n",
        "## Contexto\n",
        "El propósito de esta actividad es poner en práctica la creación y manipulación de matrices en NumPy, así como la aplicación de operaciones básicas y la comprensión del comportamiento de la indexación.\n",
        "\n",
        "## Consigna\n",
        "Crea una matriz 3x3 utilizando `np.array()` a partir de listas de listas. Luego, aplica operaciones matemáticas básicas (suma, resta y multiplicación por un escalar), y realiza una selección condicional de elementos mayores a 5. Finalmente, analiza si el resultado de una asignación es una copia o una referencia.\n",
        "\n",
        "## Paso a paso\n",
        "\n",
        "1. Importa la librería NumPy como `np`.\n",
        "2. Crea una matriz A de 3x3 con números enteros del 1 al 9.\n",
        "3. Realiza las siguientes operaciones:\n",
        "   - Suma 10 a cada elemento de la matriz.\n",
        "   - Multiplica la matriz por 2.\n",
        "   - Extrae los elementos mayores a 5 utilizando selección condicional.\n",
        "4. Asigna la matriz A a una nueva variable `B = A` y modifica un valor de B.  \n",
        "   ¿Cambió también A?\n",
        "5. Ahora usa `B = A.copy()` y repite la modificación.  \n",
        "   ¿Qué ocurrió con A esta vez?\n"
      ],
      "metadata": {
        "id": "MW87SuUVCdI-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1U95_LUJBl2N",
        "outputId": "ae751892-4d4b-424e-c5d6-ba0f49ee3193"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Matriz original A:\n",
            "[[1 2 3]\n",
            " [4 5 6]\n",
            " [7 8 9]]\n",
            "\n",
            "A + 10:\n",
            "[[11 12 13]\n",
            " [14 15 16]\n",
            " [17 18 19]]\n",
            "\n",
            "A * 2:\n",
            "[[ 2  4  6]\n",
            " [ 8 10 12]\n",
            " [14 16 18]]\n",
            "\n",
            "Elementos de A mayores a 5:\n",
            "[6 7 8 9]\n",
            "\n",
            "A después de modificar B (asignación por referencia):\n",
            "[[100   2   3]\n",
            " [  4   5   6]\n",
            " [  7   8   9]]\n",
            "\n",
            "A después de modificar B (con .copy()):\n",
            "[[1 2 3]\n",
            " [4 5 6]\n",
            " [7 8 9]]\n",
            "\n",
            "B modificado:\n",
            "[[999   2   3]\n",
            " [  4   5   6]\n",
            " [  7   8   9]]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "# 1. Crear la matriz A de 3x3 con números del 1 al 9\n",
        "A = np.array([[1, 2, 3],\n",
        "              [4, 5, 6],\n",
        "              [7, 8, 9]])\n",
        "print(\"Matriz original A:\")\n",
        "print(A)\n",
        "\n",
        "# 2. Sumar 10 a cada elemento\n",
        "A_sum10 = A + 10\n",
        "print(\"\\nA + 10:\")\n",
        "print(A_sum10)\n",
        "\n",
        "# 3. Multiplicar la matriz por 2\n",
        "A_mul2 = A * 2\n",
        "print(\"\\nA * 2:\")\n",
        "print(A_mul2)\n",
        "\n",
        "# 4. Extraer elementos mayores a 5 usando selección condicional\n",
        "mayores_5 = A[A > 5]\n",
        "print(\"\\nElementos de A mayores a 5:\")\n",
        "print(mayores_5)\n",
        "\n",
        "# 5. Asignación por referencia\n",
        "B = A\n",
        "B[0, 0] = 100\n",
        "print(\"\\nA después de modificar B (asignación por referencia):\")\n",
        "print(A)\n",
        "\n",
        "# Restaurar A para continuar con prueba por copia\n",
        "A = np.array([[1, 2, 3],\n",
        "              [4, 5, 6],\n",
        "              [7, 8, 9]])\n",
        "\n",
        "# 6. Asignación con copia\n",
        "B = A.copy()\n",
        "B[0, 0] = 999\n",
        "print(\"\\nA después de modificar B (con .copy()):\")\n",
        "print(A)\n",
        "print(\"\\nB modificado:\")\n",
        "print(B)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Clase M3 AE1-2 – Generación de datos y redimensionado\n",
        "\n",
        "## Contexto\n",
        "Esta actividad busca fortalecer el dominio sobre las funciones predefinidas de NumPy para crear arreglos, generar datos de prueba y reestructurar la forma de los mismos utilizando `reshape()`.\n",
        "\n",
        "## Consigna\n",
        "Utiliza funciones de NumPy como `np.arange()`, `np.linspace()` y `np.random.randint()` para generar distintos tipos de arreglos. Luego, redimensionalos con `reshape()` y aplica funciones matemáticas a los mismos.\n",
        "\n",
        "## Paso a paso\n",
        "\n",
        "1. Crea un arreglo `x` con `np.arange(1, 17)` y redimensionalo en una matriz de 4x4.\n",
        "2. Genera un arreglo de 10 elementos equidistantes entre 0 y 100 usando `np.linspace()`.\n",
        "3. Crea una matriz aleatoria de 3x3 con enteros entre 1 y 20 usando `np.random.randint()`.\n",
        "4. Aplica `np.sqrt()` y `np.log()` sobre las matrices creadas (cuando sea posible).\n",
        "5. Reflexiona: ¿Qué diferencias notas en la forma de aplicar funciones sobre arreglos enteros vs flotantes?\n"
      ],
      "metadata": {
        "id": "OPt90ptkDama"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# 1. Crear un arreglo del 1 al 16 y redimensionarlo en una matriz de 4x4\n",
        "x = np.arange(1, 17)\n",
        "matriz_4x4 = x.reshape(4, 4)\n",
        "print(\"Matriz 4x4 generada con arange:\")\n",
        "print(matriz_4x4)\n",
        "\n",
        "# 2. Generar un arreglo de 10 elementos equidistantes entre 0 y 100\n",
        "lineal = np.linspace(0, 100, 10)\n",
        "print(\"\\nArreglo con 10 valores equidistantes entre 0 y 100:\")\n",
        "print(lineal)\n",
        "\n",
        "# 3. Crear una matriz aleatoria 3x3 con enteros entre 1 y 20\n",
        "aleatoria = np.random.randint(1, 21, size=(3, 3))\n",
        "print(\"\\nMatriz aleatoria 3x3 con enteros entre 1 y 20:\")\n",
        "print(aleatoria)\n",
        "\n",
        "# 4. Aplicar funciones sqrt y log\n",
        "print(\"\\nRaíz cuadrada de la matriz aleatoria:\")\n",
        "print(np.sqrt(aleatoria))\n",
        "\n",
        "print(\"\\nLogaritmo natural de la matriz aleatoria:\")\n",
        "print(np.log(aleatoria))\n",
        "\n",
        "# 5. Reflexión:\n",
        "print(\"\\nReflexión:\")\n",
        "print(\"Las funciones matemáticas como sqrt() y log() se aplican directamente sobre arreglos flotantes.\")\n",
        "print(\"Si los arreglos contienen enteros, NumPy los convierte a float automáticamente para estas operaciones.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ub-CPMr6DcKC",
        "outputId": "42a56cac-873f-4033-86b8-5fbd0de320db"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Matriz 4x4 generada con arange:\n",
            "[[ 1  2  3  4]\n",
            " [ 5  6  7  8]\n",
            " [ 9 10 11 12]\n",
            " [13 14 15 16]]\n",
            "\n",
            "Arreglo con 10 valores equidistantes entre 0 y 100:\n",
            "[  0.          11.11111111  22.22222222  33.33333333  44.44444444\n",
            "  55.55555556  66.66666667  77.77777778  88.88888889 100.        ]\n",
            "\n",
            "Matriz aleatoria 3x3 con enteros entre 1 y 20:\n",
            "[[ 2 19  4]\n",
            " [ 7 17  2]\n",
            " [ 8 19  7]]\n",
            "\n",
            "Raíz cuadrada de la matriz aleatoria:\n",
            "[[1.41421356 4.35889894 2.        ]\n",
            " [2.64575131 4.12310563 1.41421356]\n",
            " [2.82842712 4.35889894 2.64575131]]\n",
            "\n",
            "Logaritmo natural de la matriz aleatoria:\n",
            "[[0.69314718 2.94443898 1.38629436]\n",
            " [1.94591015 2.83321334 0.69314718]\n",
            " [2.07944154 2.94443898 1.94591015]]\n",
            "\n",
            "Reflexión:\n",
            "Las funciones matemáticas como sqrt() y log() se aplican directamente sobre arreglos flotantes.\n",
            "Si los arreglos contienen enteros, NumPy los convierte a float automáticamente para estas operaciones.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Clase M3 AE2-1 – Primer acercamiento al análisis exploratorio con Pandas\n",
        "\n",
        "## Contexto\n",
        "El objetivo es familiarizarse con la estructura de un `DataFrame` y aplicar los métodos básicos de exploración y resumen de datos para obtener una primera comprensión de su contenido.\n",
        "\n",
        "## Consigna\n",
        "Carga un archivo CSV con Pandas y explora su contenido utilizando métodos como `head()`, `info()` y `describe()`. Luego, extrae estadísticas clave de las columnas numéricas y verifica si hay valores nulos.\n",
        "\n",
        "## Paso a paso\n",
        "\n",
        "1. Importa la librería Pandas como `pd`.\n",
        "2. Lee el archivo `data.csv` con `pd.read_csv('data.csv')` y asígnalo a una variable llamada `df`.\n",
        "3. Usa los métodos:\n",
        "   - `df.head()` para ver los primeros registros.\n",
        "   - `df.info()` para revisar estructura y tipos de datos.\n",
        "   - `df.describe()` para ver estadísticas básicas.\n",
        "4. Aplica `df.isnull().sum()` para detectar valores nulos.\n",
        "5. Usa `df.mean()`, `df.median()` y `df.std()` para obtener medidas adicionales.\n",
        "6. Comparte una breve interpretación de lo que observaste.\n"
      ],
      "metadata": {
        "id": "w5BI9R62EP3d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Cargar el archivo CSV\n",
        "df = pd.read_csv('data.csv')\n",
        "\n",
        "# Mostrar los primeros registros\n",
        "print(\"Primeros registros:\")\n",
        "print(df.head())\n",
        "\n",
        "# Información general del DataFrame\n",
        "print(\"\\nInformación del DataFrame:\")\n",
        "print(df.info())\n",
        "\n",
        "# Estadísticas descriptivas básicas\n",
        "print(\"\\nEstadísticas descriptivas:\")\n",
        "print(df.describe())\n",
        "\n",
        "# Detección de valores nulos\n",
        "print(\"\\nValores nulos por columna:\")\n",
        "print(df.isnull().sum())\n",
        "\n",
        "# Medidas adicionales\n",
        "print(\"\\nPromedios:\")\n",
        "print(df.mean(numeric_only=True))\n",
        "\n",
        "print(\"\\nMedianas:\")\n",
        "print(df.median(numeric_only=True))\n",
        "\n",
        "print(\"\\nDesviaciones estándar:\")\n",
        "print(df.std(numeric_only=True))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "px8oRgQKEqLM",
        "outputId": "c6b8f174-6089-417e-9ab3-c628372ba673"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Primeros registros:\n",
            "   Nombre  Edad  Altura  Peso\n",
            "0     Ana  23.0    1.65    55\n",
            "1    Luis  35.0    1.80    78\n",
            "2  Carlos  45.0    1.75    85\n",
            "3   Marta   NaN    1.60    60\n",
            "4   Elena  29.0     NaN    65\n",
            "\n",
            "Información del DataFrame:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 5 entries, 0 to 4\n",
            "Data columns (total 4 columns):\n",
            " #   Column  Non-Null Count  Dtype  \n",
            "---  ------  --------------  -----  \n",
            " 0   Nombre  5 non-null      object \n",
            " 1   Edad    4 non-null      float64\n",
            " 2   Altura  4 non-null      float64\n",
            " 3   Peso    5 non-null      int64  \n",
            "dtypes: float64(2), int64(1), object(1)\n",
            "memory usage: 292.0+ bytes\n",
            "None\n",
            "\n",
            "Estadísticas descriptivas:\n",
            "            Edad    Altura      Peso\n",
            "count   4.000000  4.000000   5.00000\n",
            "mean   33.000000  1.700000  68.60000\n",
            "std     9.380832  0.091287  12.54193\n",
            "min    23.000000  1.600000  55.00000\n",
            "25%    27.500000  1.637500  60.00000\n",
            "50%    32.000000  1.700000  65.00000\n",
            "75%    37.500000  1.762500  78.00000\n",
            "max    45.000000  1.800000  85.00000\n",
            "\n",
            "Valores nulos por columna:\n",
            "Nombre    0\n",
            "Edad      1\n",
            "Altura    1\n",
            "Peso      0\n",
            "dtype: int64\n",
            "\n",
            "Promedios:\n",
            "Edad      33.0\n",
            "Altura     1.7\n",
            "Peso      68.6\n",
            "dtype: float64\n",
            "\n",
            "Medianas:\n",
            "Edad      32.0\n",
            "Altura     1.7\n",
            "Peso      65.0\n",
            "dtype: float64\n",
            "\n",
            "Desviaciones estándar:\n",
            "Edad       9.380832\n",
            "Altura     0.091287\n",
            "Peso      12.541930\n",
            "dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Clase M3 AE2-2 – Práctica con Python\n",
        "\n",
        "## Objetivo\n",
        "Practicar la entrada de datos, estructuras condicionales y funciones básicas en Python mediante un ejercicio cotidiano.\n",
        "\n",
        "## Consigna\n",
        "Desarrolla un programa que interactúe con el usuario solicitando su nombre y edad. Luego, determina si la persona es mayor o menor de edad, e imprime un mensaje correspondiente.\n",
        "\n",
        "## Paso a paso\n",
        "\n",
        "1. Abre tu entorno de trabajo preferido (VS Code, Jupyter, Colab, etc.).\n",
        "2. Crea un nuevo archivo o celda de código.\n",
        "3. Escribe un programa que:\n",
        "   - Solicite al usuario su **nombre** y **edad**.\n",
        "   - Utilice una estructura condicional (`if`) para verificar si es **mayor** o **menor de edad**.\n",
        "   - Imprima un mensaje de saludo que incluya el nombre y la condición (mayor o menor).\n",
        "4. Prueba el programa con distintas edades para verificar su correcto funcionamiento.\n",
        "5. *(Opcional)* Agrega una función llamada `es_mayor()` que reciba la edad como argumento y retorne `True` si es mayor de edad, o `False` si no lo es.\n"
      ],
      "metadata": {
        "id": "_7iN3SfxFJ7c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ejercicio AE2-1 - Práctica con Python\n",
        "\n",
        "# Solicita el nombre y edad del usuario\n",
        "nombre = input(\"Ingrese su nombre: \")\n",
        "edad = int(input(\"Ingrese su edad: \"))\n",
        "\n",
        "# Verifica si es mayor o menor de edad\n",
        "if edad >= 18:\n",
        "    print(f\"Hola {nombre}, eres mayor de edad.\")\n",
        "else:\n",
        "    print(f\"Hola {nombre}, eres menor de edad.\")\n",
        "\n",
        "# Probar con distintas edades asegura que el código funciona correctamente\n",
        "\n",
        "# Función opcional: determinar si alguien es mayor de edad\n",
        "def es_mayor(edad):\n",
        "    return edad >= 18\n",
        "\n",
        "# Prueba de la función\n",
        "resultado = es_mayor(edad)\n",
        "print(f\"¿Es mayor de edad según la función? {resultado}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wmD-vy4QFPNL",
        "outputId": "5b1ecf87-ac33-4925-f1cf-20bba6e66401"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ingrese su nombre: Fabian\n",
            "Ingrese su edad: 33\n",
            "Hola Fabian, eres mayor de edad.\n",
            "¿Es mayor de edad según la función? True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Clase M3 AE3-1 – Exploración de archivos CSV\n",
        "\n",
        "## Contexto\n",
        "Aprenderemos a importar datos desde archivos `.csv`, comprender su estructura y aplicar buenas prácticas para la carga de datos tabulares en Python con Pandas.\n",
        "\n",
        "## Consigna\n",
        "Usa Pandas para cargar un archivo `.csv`, inspecciona su contenido y exporta una versión modificada del archivo, aplicando algunas transformaciones básicas.\n",
        "\n",
        "## Paso a paso\n",
        "\n",
        "1. Importa la librería `pandas` (import pandas as pd).  \n",
        "   Cargá un archivo CSV con `pd.read_csv('archivo.csv')`.\n",
        "\n",
        "2. Visualiza las primeras filas con `df.head()` y revisá la estructura general con `df.info()`.\n",
        "\n",
        "3. Renombra las columnas manualmente si no hay encabezado (`header=None`, `names=[]`).\n",
        "\n",
        "4. Detecta valores nulos con `df.isnull().sum()` y reemplázalos si es necesario.\n",
        "\n",
        "5. Exporta el `DataFrame` modificado a un nuevo archivo CSV:  \n",
        "   `df.to_csv('nuevo_archivo.csv', index=False)`\n"
      ],
      "metadata": {
        "id": "W5Roc72nFmuN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Importar la librería\n",
        "import pandas as pd\n",
        "\n",
        "# 2. Cargar el archivo CSV desde URL pública\n",
        "url = 'https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv'\n",
        "df = pd.read_csv(url)\n",
        "\n",
        "# 3. Visualizar las primeras filas y estructura general\n",
        "print(\"Primeras filas del dataset:\")\n",
        "print(df.head())\n",
        "\n",
        "print(\"\\nInformación general del DataFrame:\")\n",
        "print(df.info())\n",
        "\n",
        "# 4. Verificar valores nulos\n",
        "print(\"\\nValores nulos por columna:\")\n",
        "print(df.isnull().sum())\n",
        "\n",
        "# 5. Reemplazar valores nulos en la columna 'Age' con la media\n",
        "df['Age'] = df['Age'].fillna(df['Age'].mean())\n",
        "\n",
        "# 6. Exportar el DataFrame modificado a un nuevo archivo CSV\n",
        "df.to_csv('titanic_modificado.csv', index=False)\n",
        "print(\"\\nArchivo exportado exitosamente como 'titanic_modificado.csv'\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rIncg11YFpgr",
        "outputId": "f9e03772-54f9-4e6a-ecff-0e1d56dcbbef"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Primeras filas del dataset:\n",
            "   PassengerId  Survived  Pclass  \\\n",
            "0            1         0       3   \n",
            "1            2         1       1   \n",
            "2            3         1       3   \n",
            "3            4         1       1   \n",
            "4            5         0       3   \n",
            "\n",
            "                                                Name     Sex   Age  SibSp  \\\n",
            "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
            "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
            "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
            "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
            "4                           Allen, Mr. William Henry    male  35.0      0   \n",
            "\n",
            "   Parch            Ticket     Fare Cabin Embarked  \n",
            "0      0         A/5 21171   7.2500   NaN        S  \n",
            "1      0          PC 17599  71.2833   C85        C  \n",
            "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
            "3      0            113803  53.1000  C123        S  \n",
            "4      0            373450   8.0500   NaN        S  \n",
            "\n",
            "Información general del DataFrame:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 891 entries, 0 to 890\n",
            "Data columns (total 12 columns):\n",
            " #   Column       Non-Null Count  Dtype  \n",
            "---  ------       --------------  -----  \n",
            " 0   PassengerId  891 non-null    int64  \n",
            " 1   Survived     891 non-null    int64  \n",
            " 2   Pclass       891 non-null    int64  \n",
            " 3   Name         891 non-null    object \n",
            " 4   Sex          891 non-null    object \n",
            " 5   Age          714 non-null    float64\n",
            " 6   SibSp        891 non-null    int64  \n",
            " 7   Parch        891 non-null    int64  \n",
            " 8   Ticket       891 non-null    object \n",
            " 9   Fare         891 non-null    float64\n",
            " 10  Cabin        204 non-null    object \n",
            " 11  Embarked     889 non-null    object \n",
            "dtypes: float64(2), int64(5), object(5)\n",
            "memory usage: 83.7+ KB\n",
            "None\n",
            "\n",
            "Valores nulos por columna:\n",
            "PassengerId      0\n",
            "Survived         0\n",
            "Pclass           0\n",
            "Name             0\n",
            "Sex              0\n",
            "Age            177\n",
            "SibSp            0\n",
            "Parch            0\n",
            "Ticket           0\n",
            "Fare             0\n",
            "Cabin          687\n",
            "Embarked         2\n",
            "dtype: int64\n",
            "\n",
            "Archivo exportado exitosamente como 'titanic_modificado.csv'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Clase M3 AE3-2 – Lectura desde Excel y extracción de tablas web\n",
        "\n",
        "## Contexto\n",
        "Experimentaremos con la importación de datos desde diferentes fuentes: un archivo de Excel y una tabla HTML, usando Pandas como herramienta central.\n",
        "\n",
        "## Consigna\n",
        "Lee un archivo de Excel desde tu equipo y extrae una tabla HTML desde una página web utilizando Pandas. Explora ambos conjuntos de datos y guarda una copia en archivos locales.\n",
        "\n",
        "## Paso a paso\n",
        "\n",
        "1. Asegúrate de tener instalada la librería `openpyxl` para poder leer archivos `.xlsx`.\n",
        "\n",
        "2. Lee un archivo Excel con:\n",
        "\n",
        "   ```python\n",
        "   df_excel = pd.read_excel('archivo.xlsx')\n",
        "   ```\n",
        "\n",
        "   - Si hay múltiples hojas, puedes cargarlas así:\n",
        "\n",
        "   ```python\n",
        "   df_hoja = pd.read_excel('archivo.xlsx', sheet_name='NombreDeHoja')\n",
        "   ```\n",
        "\n",
        "3. Busca una URL que contenga una tabla HTML simple (o usa una proporcionada por el docente).\n",
        "\n",
        "4. Utiliza `pd.read_html('url')` para importar la tabla.  \n",
        "   Esto devuelve una **lista de DataFrames**, por ejemplo:\n",
        "\n",
        "   ```python\n",
        "   tablas = pd.read_html('https://url-de-ejemplo.com')\n",
        "   df_html = tablas[0]  # selecciona la primera tabla\n",
        "   ```\n",
        "\n",
        "5. Explora los datos con los métodos `head()` y `describe()`:\n",
        "\n",
        "   ```python\n",
        "   print(df_excel.head())\n",
        "   print(df_excel.describe())\n",
        "\n",
        "   print(df_html.head())\n",
        "   print(df_html.describe())\n",
        "   ```\n",
        "\n",
        "6. Exporta ambos conjuntos de datos como nuevos archivos:\n",
        "\n",
        "   ```python\n",
        "   df_excel.to_excel('archivo_nuevo.xlsx', index=False)\n",
        "   df_html.to_csv('archivo_nuevo.csv', index=False)\n",
        "   ```\n"
      ],
      "metadata": {
        "id": "2rZ9eaeWKBsp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Leer archivo Excel\n",
        "df_excel = pd.read_excel('archivo_ejemplo.xlsx')\n",
        "\n",
        "# Leer tabla HTML desde Wikipedia\n",
        "url = 'https://es.wikipedia.org/wiki/Anexo:Pa%C3%ADses_por_PIB_(nominal)'\n",
        "tablas = pd.read_html(url)\n",
        "\n",
        "# Seleccionamos la primera tabla útil\n",
        "df_html = tablas[1]\n",
        "\n",
        "# Exploramos ambos datasets\n",
        "print(\"Datos desde Excel:\")\n",
        "print(df_excel.head())\n",
        "print(df_excel.describe())\n",
        "\n",
        "print(\"\\nDatos desde HTML:\")\n",
        "print(df_html.head())\n",
        "print(df_html.describe())\n",
        "\n",
        "# Exportamos ambos datasets\n",
        "df_excel.to_excel('archivo_excel_modificado.xlsx', index=False)\n",
        "df_html.to_csv('archivo_html_extraido.csv', index=False)\n",
        "\n",
        "print(\"\\nArchivos exportados exitosamente.\")\n"
      ],
      "metadata": {
        "id": "Y7Ojp-gYHnpw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af1ed495-2dfe-4feb-b072-258f03903d84"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Datos desde Excel:\n",
            "   Producto  Precio  Stock\n",
            "0    Laptop  800000     25\n",
            "1   Monitor  200000     40\n",
            "2   Teclado   30000    150\n",
            "3     Mouse   15000    200\n",
            "4  Parlante   50000     60\n",
            "              Precio       Stock\n",
            "count       5.000000    5.000000\n",
            "mean   219000.000000   95.000000\n",
            "std    333099.084358   76.157731\n",
            "min     15000.000000   25.000000\n",
            "25%     30000.000000   40.000000\n",
            "50%     50000.000000   60.000000\n",
            "75%    200000.000000  150.000000\n",
            "max    800000.000000  200.000000\n",
            "\n",
            "Datos desde HTML:\n",
            "                                                   0  \\\n",
            "0  Lista según el Fondo Monetario Internacional (...   \n",
            "1                                               Pos.   \n",
            "2                                                NaN   \n",
            "3                                                  1   \n",
            "4                                                  2   \n",
            "\n",
            "                                                   1  \\\n",
            "0  Lista según el Banco Mundial de (2022)[4]​ Pos...   \n",
            "1                                               País   \n",
            "2                                              Mundo   \n",
            "3                                     Estados Unidos   \n",
            "4                                              China   \n",
            "\n",
            "                                                   2    3  \n",
            "0  Lista según The World Factbook de la CIA (2000...  NaN  \n",
            "1                      PIB nominal (millones de USD)  NaN  \n",
            "2                                        104 476 432  NaN  \n",
            "3                                         26 949 643  NaN  \n",
            "4                                         17 700 899  NaN  \n",
            "          0    1    2     3\n",
            "count   584  559  613   417\n",
            "unique  196  248  612   208\n",
            "top       —    1  939  2017\n",
            "freq      8   45    2   191\n",
            "\n",
            "Archivos exportados exitosamente.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Clase M3 AE4 - Ejercicio N° 1  \n",
        "### Carga y exportación de archivos CSV\n",
        "\n",
        "### Contexto\n",
        "\n",
        "En esta actividad, los estudiantes aprenderán a importar datos desde archivos `.csv`, adaptarlos a las necesidades del análisis, y luego exportarlos nuevamente con las configuraciones adecuadas.\n",
        "\n",
        "### Consigna\n",
        "\n",
        "Utiliza la librería **Pandas** para cargar un archivo `.csv` sin encabezado, renombra las columnas, limpia los datos nulos y exporta el resultado a un nuevo archivo `.csv` con delimitador personalizado.\n",
        "\n",
        "### Paso a paso:\n",
        "\n",
        "1. Abre tu entorno de trabajo preferido (VS Code, Jupyter, Colab, etc.).\n",
        "2. Importa Pandas (`import pandas as pd`).\n",
        "3. Lee el archivo `datos.csv` usando `header=None` y asigna nombres personalizados con  \n",
        "   `names=['nombre', 'edad', 'ciudad']`.\n",
        "4. Reemplaza valores nulos o símbolos como `'?'` usando `na_values` y `fillna()`.\n",
        "5. Elimina filas duplicadas si las hubiera con `drop_duplicates()`.\n",
        "6. Exporta el DataFrame limpio con `to_csv()`, usando `sep=';'` y `encoding='utf-8'`.\n",
        "\n"
      ],
      "metadata": {
        "id": "spuNvVn5Kid0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Paso 1: Cargar archivo CSV sin encabezado y asignar nombres de columnas\n",
        "print(\"Paso 1: Cargando el archivo CSV sin encabezado y asignando nombres de columnas...\")\n",
        "column_names = ['nombre', 'edad', 'ciudad']\n",
        "df = pd.read_csv('/content/datos.csv', header=None, names=column_names)\n",
        "print(df.head())\n",
        "\n",
        "# Paso 2: Reemplazar símbolos '?' por valores nulos y luego imputarlos con fillna\n",
        "print(\"\\nPaso 2: Reemplazando símbolos '?' por NaN y llenando con valores por defecto...\")\n",
        "df.replace('?', pd.NA, inplace=True)\n",
        "df['edad'] = df['edad'].fillna(df['edad'].mode()[0])\n",
        "df['ciudad'] = df['ciudad'].fillna('Desconocida')\n",
        "df['nombre'] = df['nombre'].fillna('Anónimo')\n",
        "print(df.head())\n",
        "\n",
        "# Paso 3: Eliminar filas duplicadas\n",
        "print(\"\\nPaso 3: Eliminando filas duplicadas si existen...\")\n",
        "df.drop_duplicates(inplace=True)\n",
        "print(df.head())\n",
        "\n",
        "# Paso 4: Exportar DataFrame limpio a nuevo archivo CSV\n",
        "print(\"\\nPaso 4: Exportando archivo limpio...\")\n",
        "output_path = 'datos_limpios.csv'\n",
        "df.to_csv(output_path, sep=';', index=False, encoding='utf-8')\n",
        "print(f\"Datos exportados correctamente a: {output_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mUS_dfkMLFkh",
        "outputId": "c3231dfc-78f6-449f-fd7e-c0ef81fed32d"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Paso 1: Cargando el archivo CSV sin encabezado y asignando nombres de columnas...\n",
            "  nombre edad      ciudad\n",
            "0   Juan   25    Santiago\n",
            "1    Ana   30  Valparaíso\n",
            "2  Pedro    ?  Concepción\n",
            "3  Laura   28    Santiago\n",
            "4   Juan   25    Santiago\n",
            "\n",
            "Paso 2: Reemplazando símbolos '?' por NaN y llenando con valores por defecto...\n",
            "  nombre edad      ciudad\n",
            "0   Juan   25    Santiago\n",
            "1    Ana   30  Valparaíso\n",
            "2  Pedro   25  Concepción\n",
            "3  Laura   28    Santiago\n",
            "4   Juan   25    Santiago\n",
            "\n",
            "Paso 3: Eliminando filas duplicadas si existen...\n",
            "    nombre edad      ciudad\n",
            "0     Juan   25    Santiago\n",
            "1      Ana   30  Valparaíso\n",
            "2    Pedro   25  Concepción\n",
            "3    Laura   28    Santiago\n",
            "5  Anónimo   22      Temuco\n",
            "\n",
            "Paso 4: Exportando archivo limpio...\n",
            "Datos exportados correctamente a: datos_limpios.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ejercicio N°2: Lectura de datos desde Excel y extracción web\n",
        "\n",
        "### Contexto\n",
        "Comprender cómo obtener datos desde archivos Excel y páginas web, y cómo unificarlos en un solo DataFrame para análisis conjunto.\n",
        "\n",
        "### Consigna\n",
        "Lee datos desde un archivo `.xlsx` y desde una tabla HTML de una web. Combina ambos conjuntos en un solo DataFrame y exporta el resultado como archivo Excel con múltiples hojas.\n",
        "\n",
        "### Paso a paso:\n",
        "1. Asegúrate de tener instalada la librería `openpyxl`.\n",
        "2. Carga un archivo Excel con `read_excel('archivo.xlsx', sheet_name='Ventas')`.\n",
        "3. Usa `read_html()` para extraer la primera tabla de una web (por ejemplo, una página de estadísticas).\n",
        "4. Unifica ambos conjuntos con `concat()` o `merge()` según el caso.\n",
        "5. Exporta el resultado a un archivo `resumen.xlsx` con `to_excel()`, incluyendo ambos DataFrames en hojas diferentes usando `ExcelWriter`.\n"
      ],
      "metadata": {
        "id": "vSnZzm1LMTzg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Paso 1: Asegurarse de tener instalada la libreria openpyxl\n",
        "#ya está instalada en colab\n",
        "\n",
        "# Paso 2: Cargar archivo Excel\n",
        "print(\"\\nPaso 2: Cargando hoja 'Ventas' desde archivo Excel...\")\n",
        "df_excel = pd.read_excel('/content/archivo_ventas.xlsx', sheet_name='Ventas')\n",
        "print(df_excel.head())\n",
        "\n",
        "# Paso 3: Extraer tabla desde una pagina web\n",
        "print(\"\\nPaso 3: Extrayendo primera tabla desde pagina web...\")\n",
        "url = 'https://es.wikipedia.org/wiki/Demografia_de_Chile'\n",
        "df_web_list = pd.read_html(url)\n",
        "df_web = df_web_list[0]  # primera tabla encontrada\n",
        "print(df_web.head())\n",
        "\n",
        "# Paso 4: Unificar los DataFrames\n",
        "print(\"\\nPaso 4: Unificando los conjuntos de datos...\")\n",
        "df_combined = pd.concat([df_excel, df_web], axis=0, ignore_index=True)\n",
        "print(df_combined.head())\n",
        "\n",
        "# Paso 5: Exportar a archivo Excel con multiples hojas\n",
        "print(\"\\nPaso 5: Exportando a archivo Excel con multiples hojas...\")\n",
        "output_excel = 'resumen.xlsx'\n",
        "with pd.ExcelWriter(output_excel, engine='openpyxl') as writer:\n",
        "    df_excel.to_excel(writer, sheet_name='Ventas', index=False)\n",
        "    df_web.to_excel(writer, sheet_name='TablaWeb', index=False)\n",
        "    df_combined.to_excel(writer, sheet_name='Combinado', index=False)\n",
        "\n",
        "print(f\"\\nExportacion completada: {output_excel}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SX4roOpaMdaS",
        "outputId": "44f531e3-e43f-472a-95ad-71c0b88e006c"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Paso 2: Cargando hoja 'Ventas' desde archivo Excel...\n",
            "   ID   Producto  Cantidad  PrecioUnitario\n",
            "0   1    Teclado        10           15000\n",
            "1   2      Mouse        25            8000\n",
            "2   3    Monitor         8          120000\n",
            "3   4   Notebook        15          450000\n",
            "4   5  Impresora         5           90000\n",
            "\n",
            "Paso 3: Extrayendo primera tabla desde pagina web...\n",
            "   Demografía de Chile  Demografía de Chile.1  Demografía de Chile.2\n",
            "0                  NaN                    NaN                    NaN\n",
            "1            Población  18 480 432 (2024)[1]​  18 480 432 (2024)[1]​\n",
            "2             Densidad          24,44 hab/km²          24,44 hab/km²\n",
            "3  Tasa de crecimiento                   1397                   1397\n",
            "4    Tasa de natalidad       11,99 (2020)[2]​       11,99 (2020)[2]​\n",
            "\n",
            "Paso 4: Unificando los conjuntos de datos...\n",
            "    ID   Producto  Cantidad  PrecioUnitario Demografía de Chile  \\\n",
            "0  1.0    Teclado      10.0         15000.0                 NaN   \n",
            "1  2.0      Mouse      25.0          8000.0                 NaN   \n",
            "2  3.0    Monitor       8.0        120000.0                 NaN   \n",
            "3  4.0   Notebook      15.0        450000.0                 NaN   \n",
            "4  5.0  Impresora       5.0         90000.0                 NaN   \n",
            "\n",
            "  Demografía de Chile.1 Demografía de Chile.2  \n",
            "0                   NaN                   NaN  \n",
            "1                   NaN                   NaN  \n",
            "2                   NaN                   NaN  \n",
            "3                   NaN                   NaN  \n",
            "4                   NaN                   NaN  \n",
            "\n",
            "Paso 5: Exportando a archivo Excel con multiples hojas...\n",
            "\n",
            "Exportacion completada: resumen.xlsx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Clase M3 AE4 - Ejercicio N° 1  \n",
        "### Limpieza de datos de un e-commerce\n",
        "\n",
        "### Contexto\n",
        "Una tienda online desea analizar las ventas del último año. Sin embargo, los datos provienen de múltiples fuentes y presentan problemas comunes como:\n",
        "\n",
        "- Valores nulos\n",
        "- Filas duplicadas\n",
        "- Formatos inconsistentes\n",
        "\n",
        "### Objetivo\n",
        "Aplicar técnicas de limpieza de datos usando Pandas para preparar el archivo `ventas_ecommerce.csv` para su análisis.\n",
        "\n",
        "### Instrucciones\n",
        "\n",
        "1. **Carga el dataset** usando `pd.read_csv()`.\n",
        "2. **Elimina filas duplicadas** utilizando `drop_duplicates()`.\n",
        "3. **Detecta valores nulos** con `isnull()` o `info()` y decide si imputar con `fillna()` o eliminar filas.\n",
        "4. **Corrige valores mal escritos** en la columna `Método de pago` (por ejemplo, \"tarjeta\", \"efetivo\") usando `replace()`.\n",
        "5. **Asegúrate de que:**\n",
        "   - Las fechas estén en formato `datetime` (`pd.to_datetime()`).\n",
        "   - Los precios estén en tipo `float` (`astype(float)` o `pd.to_numeric()`).\n",
        "\n"
      ],
      "metadata": {
        "id": "NwNL6cvjNWP1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Paso 1: Cargar el dataset\n",
        "df = pd.read_csv(\"ventas_ecommerce.csv\")\n",
        "print(\"Vista inicial del dataset:\")\n",
        "print(df.head())\n",
        "\n",
        "# Paso 2: Eliminar filas duplicadas\n",
        "df = df.drop_duplicates()\n",
        "print(f\"Cantidad de filas luego de eliminar duplicados: {df.shape[0]}\")\n",
        "\n",
        "# Paso 3: Detectar valores nulos y tratarlos\n",
        "print(\"Valores nulos por columna:\")\n",
        "print(df.isnull().sum())\n",
        "\n",
        "# Rellenar valores nulos en 'Metodo_pago'\n",
        "df[\"Metodo_pago\"] = df[\"Metodo_pago\"].fillna(\"desconocido\")\n",
        "\n",
        "# Eliminar filas con valores nulos en 'precio'\n",
        "df = df.dropna(subset=[\"precio\"])\n",
        "\n",
        "# Paso 4: Corregir valores incorrectos en 'Metodo_pago'\n",
        "df[\"Metodo_pago\"] = df[\"Metodo_pago\"].replace({\n",
        "    \"efetivo\": \"efectivo\",\n",
        "    \"tarjeeta\": \"tarjeta\",\n",
        "    \"Tarjeta\": \"tarjeta\"\n",
        "})\n",
        "print(\"Valores únicos en 'Metodo_pago':\")\n",
        "print(df[\"Metodo_pago\"].value_counts())\n",
        "\n",
        "# Paso 5: Normalizar formatos\n",
        "df[\"fecha\"] = pd.to_datetime(df[\"fecha\"], errors=\"coerce\")\n",
        "df[\"precio\"] = pd.to_numeric(df[\"precio\"], errors=\"coerce\")\n",
        "\n",
        "# Eliminar filas con errores de conversión\n",
        "df = df.dropna(subset=[\"fecha\", \"precio\"])\n",
        "print(\"Tipos de datos después de la conversión:\")\n",
        "print(df.dtypes)\n",
        "\n",
        "# Exportar archivo limpio\n",
        "df.to_csv(\"ventas_ecommerce_limpio.csv\", index=False)\n",
        "print(\"Archivo limpio exportado como ventas_ecommerce_limpio.csv\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pycc16dtNk3f",
        "outputId": "c9194a0f-00b7-47fd-ca2f-8d8b22f7a977"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vista inicial del dataset:\n",
            "   id producto  precio       fecha Metodo_pago\n",
            "0   1   Laptop  899.99  2024-10-01     tarjeta\n",
            "1   2    Mouse   19.99  2024-10-01     efetivo\n",
            "2   3  Teclado   29.99  2024-10-02    tarjeeta\n",
            "3   3  Teclado   29.99  2024-10-02         NaN\n",
            "4   4  Monitor     abc       error     Tarjeta\n",
            "Cantidad de filas luego de eliminar duplicados: 9\n",
            "Valores nulos por columna:\n",
            "id             0\n",
            "producto       0\n",
            "precio         1\n",
            "fecha          0\n",
            "Metodo_pago    1\n",
            "dtype: int64\n",
            "Valores únicos en 'Metodo_pago':\n",
            "Metodo_pago\n",
            "tarjeta        4\n",
            "efectivo       3\n",
            "desconocido    1\n",
            "Name: count, dtype: int64\n",
            "Tipos de datos después de la conversión:\n",
            "id                      int64\n",
            "producto               object\n",
            "precio                float64\n",
            "fecha          datetime64[ns]\n",
            "Metodo_pago            object\n",
            "dtype: object\n",
            "Archivo limpio exportado como ventas_ecommerce_limpio.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ejercicio Nº 2  \n",
        "### Transformación y enriquecimiento de datos de RRHH\n",
        "\n",
        "**Contexto:**  \n",
        "Un área de Recursos Humanos necesita preparar un informe de rotación laboral con datos de empleados.  \n",
        "Se requiere agrupar, discretizar y enriquecer la información.\n",
        "\n",
        "**Consigna:**  \n",
        "Aplica transformaciones avanzadas a un dataset de empleados (`empleados.csv`) para crear nuevas variables  \n",
        "y preparar los datos para análisis.\n",
        "\n",
        "**Paso a paso:**\n",
        "1. Agrupa los empleados por área y calcula el promedio de antigüedad y edad.\n",
        "2. Discretiza la edad en categorías:\n",
        "   - Joven (≤30)\n",
        "   - Medio (31–45)\n",
        "   - Senior (46+)\n",
        "3. Crea una nueva columna con `apply()` para clasificar empleados según su permanencia:  \n",
        "   - Si Antigüedad > 5 años → “Estable”\n",
        "4. Exporta el nuevo DataFrame limpio con `to_csv()`.\n",
        "\n",
        "**Tiempo estimado:** 30 minutos\n"
      ],
      "metadata": {
        "id": "PFStWI_FOjap"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Paso 1: Cargar el dataset\n",
        "df = pd.read_csv('/content/empleados.csv')\n",
        "print(\"Paso 1: Dataset cargado:\")\n",
        "print(df.head())\n",
        "\n",
        "# Paso 2: Agrupar por área y calcular promedio de edad y antigüedad\n",
        "print(\"\\nPaso 2: Promedio de edad y antigüedad por área:\")\n",
        "agrupado = df.groupby('Área')[['Edad', 'Antigüedad']].mean()\n",
        "print(agrupado)\n",
        "\n",
        "# Paso 3: Discretizar la edad en categorías\n",
        "def categorizar_edad(edad):\n",
        "    if edad <= 30:\n",
        "        return 'Joven'\n",
        "    elif edad <= 45:\n",
        "        return 'Medio'\n",
        "    else:\n",
        "        return 'Senior'\n",
        "\n",
        "df['Categoria_Edad'] = df['Edad'].apply(categorizar_edad)\n",
        "print(\"\\nPaso 3: Edad categorizada:\")\n",
        "print(df[['Nombre', 'Edad', 'Categoria_Edad']].head())\n",
        "\n",
        "# Paso 4: Crear columna de permanencia\n",
        "df['Permanencia'] = df['Antigüedad'].apply(lambda x: 'Estable' if x > 5 else 'No Estable')\n",
        "print(\"\\nPaso 4: Columna de permanencia creada:\")\n",
        "print(df[['Nombre', 'Antigüedad', 'Permanencia']].head())\n",
        "\n",
        "# Paso 5: Exportar el nuevo DataFrame limpio\n",
        "df.to_csv('/content/empleados_limpio.csv', index=False)\n",
        "print(\"\\nPaso 5: Archivo exportado correctamente como empleados_limpio.csv\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aItvg_M2OpK4",
        "outputId": "0c779d68-8afc-466a-aa1d-26cc802cba6a"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Paso 1: Dataset cargado:\n",
            "   ID  Nombre  Edad  Antigüedad              Área\n",
            "0   1     Ana    28           2            Ventas\n",
            "1   2    Luis    35           7                TI\n",
            "2   3  Carlos    50          10                TI\n",
            "3   4   Marta    42           4  Recursos Humanos\n",
            "4   5   Pedro    23           1            Ventas\n",
            "\n",
            "Paso 2: Promedio de edad y antigüedad por área:\n",
            "                       Edad  Antigüedad\n",
            "Área                                   \n",
            "Finanzas          42.500000   10.000000\n",
            "Recursos Humanos  35.500000    3.500000\n",
            "TI                38.666667    7.666667\n",
            "Ventas            32.000000    2.666667\n",
            "\n",
            "Paso 3: Edad categorizada:\n",
            "   Nombre  Edad Categoria_Edad\n",
            "0     Ana    28          Joven\n",
            "1    Luis    35          Medio\n",
            "2  Carlos    50         Senior\n",
            "3   Marta    42          Medio\n",
            "4   Pedro    23          Joven\n",
            "\n",
            "Paso 4: Columna de permanencia creada:\n",
            "   Nombre  Antigüedad Permanencia\n",
            "0     Ana           2  No Estable\n",
            "1    Luis           7     Estable\n",
            "2  Carlos          10     Estable\n",
            "3   Marta           4  No Estable\n",
            "4   Pedro           1  No Estable\n",
            "\n",
            "Paso 5: Archivo exportado correctamente como empleados_limpio.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Clase M3 AE6 - Ejercicio N°1 - Análisis de ventas por categoría\n",
        "\n",
        "### Contexto\n",
        "Una empresa de retail necesita analizar sus ventas segmentadas por categoría de producto y mes, para preparar un informe de performance.\n",
        "\n",
        "### Consigna\n",
        "Utiliza técnicas de agrupamiento y pivoteado con Pandas para construir un resumen tabular de ventas mensuales por categoría.\n",
        "\n",
        "### Paso a paso:\n",
        "1. Carga el archivo `ventas_productos.csv` (contiene columnas como fecha, categoría, producto, ventas).\n",
        "2. Convertí la columna fecha a tipo datetime y extraé el mes en una nueva columna.\n",
        "3. Agrupá por categoría y mes usando `groupby()` y calculá la suma de ventas.\n",
        "4. Pivotá el resultado para que las categorías estén en filas y los meses en columnas.\n",
        "5. Exportá el DataFrame pivotado como `reporte_categorias.csv`.\n",
        "\n"
      ],
      "metadata": {
        "id": "QXxvEmaRPmBX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Paso 1: Cargar el archivo CSV\n",
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('/content/ventas_productos.csv')\n",
        "print(\"Paso 1: Dataset cargado\")\n",
        "print(df.head())\n",
        "\n",
        "# Paso 2: Convertir la columna fecha a tipo datetime y extraer el mes\n",
        "df['fecha'] = pd.to_datetime(df['fecha'])\n",
        "df['mes'] = df['fecha'].dt.month\n",
        "print(\"\\nPaso 2: Fecha convertida a datetime y mes extraído\")\n",
        "print(df[['fecha', 'mes']].head())\n",
        "\n",
        "# Paso 3: Agrupar por categoría y mes, calcular suma de ventas\n",
        "df_grouped = df.groupby(['categoria', 'mes'])['ventas'].sum().reset_index()\n",
        "print(\"\\nPaso 3: Agrupamiento por categoría y mes\")\n",
        "print(df_grouped.head())\n",
        "\n",
        "# Paso 4: Pivotear el resultado (categorías como filas y meses como columnas)\n",
        "df_pivot = df_grouped.pivot(index='categoria', columns='mes', values='ventas')\n",
        "print(\"\\nPaso 4: Pivot de la tabla\")\n",
        "print(df_pivot)\n",
        "\n",
        "# Paso 5: Exportar el resultado a un nuevo archivo CSV\n",
        "df_pivot.to_csv('/content/reporte_categorias.csv')\n",
        "print(\"\\nPaso 5: Archivo exportado como reporte_categorias.csv\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KmETrzEhP0pw",
        "outputId": "08f5c396-966f-4243-f6cf-455b9daab95f"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Paso 1: Dataset cargado\n",
            "        fecha    categoria     producto  ventas\n",
            "0  2025-01-15  Electrónica       Laptop    1000\n",
            "1  2025-01-20  Electrónica       Tablet     800\n",
            "2  2025-02-10  Electrónica   Smartphone    1200\n",
            "3  2025-02-18  Electrónica  Auriculares     600\n",
            "4  2025-03-05  Electrónica      Monitor     900\n",
            "\n",
            "Paso 2: Fecha convertida a datetime y mes extraído\n",
            "       fecha  mes\n",
            "0 2025-01-15    1\n",
            "1 2025-01-20    1\n",
            "2 2025-02-10    2\n",
            "3 2025-02-18    2\n",
            "4 2025-03-05    3\n",
            "\n",
            "Paso 3: Agrupamiento por categoría y mes\n",
            "     categoria  mes  ventas\n",
            "0  Electrónica    1    1800\n",
            "1  Electrónica    2    1800\n",
            "2  Electrónica    3    1600\n",
            "3         Ropa    1     500\n",
            "4         Ropa    2     650\n",
            "\n",
            "Paso 4: Pivot de la tabla\n",
            "mes             1     2     3\n",
            "categoria                    \n",
            "Electrónica  1800  1800  1600\n",
            "Ropa          500   650   900\n",
            "\n",
            "Paso 5: Archivo exportado como reporte_categorias.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Clase M3 AE6 - Ejercicio 2: Integración de datos de usuarios y compras\n",
        "\n",
        "### Contexto:\n",
        "El equipo de marketing quiere unir datos de usuarios registrados con sus compras, para identificar patrones de comportamiento.\n",
        "\n",
        "### Consigna:\n",
        "Aplica `merge()` y `groupby()` en Pandas para analizar cuántas compras hizo cada tipo de usuario.\n",
        "\n",
        "### Paso a paso:\n",
        "\n",
        "1. Carga dos archivos:  \n",
        "   - `usuarios.csv` (con columnas `user_id`, `segmento`, `registro_fecha`)  \n",
        "   - `compras.csv` (con columnas `user_id`, `compra_id`, `monto`)\n",
        "\n",
        "2. Unir ambos datasets utilizando `merge()` por `user_id`.\n",
        "\n",
        "3. Agrupar por `segmento` y contar la cantidad de compras realizadas.\n",
        "\n",
        "4. Calcular también el monto total gastado por segmento usando `.agg()`.\n",
        "\n",
        "5. Mostrar los resultados ordenados de mayor a menor cantidad de compras.\n"
      ],
      "metadata": {
        "id": "4pokJ--uQlR9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Paso 1: Cargar los archivos usuarios.csv y compras.csv\n",
        "df_usuarios = pd.read_csv('/content/usuarios.csv')\n",
        "df_compras = pd.read_csv('/content/compras.csv')\n",
        "\n",
        "print(\"Usuarios:\")\n",
        "print(df_usuarios.head())\n",
        "print(\"\\nCompras:\")\n",
        "print(df_compras.head())\n",
        "\n",
        "# Paso 2: Unir los datasets por 'user_id'\n",
        "df_merged = pd.merge(df_usuarios, df_compras, on='user_id')\n",
        "print(\"\\nMerge realizado:\")\n",
        "print(df_merged.head())\n",
        "\n",
        "# Paso 3: Agrupar por segmento y contar cantidad de compras\n",
        "compras_por_segmento = df_merged.groupby('segmento')['compra_id'].count().reset_index()\n",
        "compras_por_segmento.rename(columns={'compra_id': 'cantidad_compras'}, inplace=True)\n",
        "\n",
        "# Paso 4: Calcular el monto total gastado por segmento\n",
        "monto_por_segmento = df_merged.groupby('segmento')['monto'].sum().reset_index()\n",
        "monto_por_segmento.rename(columns={'monto': 'monto_total'}, inplace=True)\n",
        "\n",
        "# Paso 5: Unir ambos resultados y ordenar por cantidad de compras descendente\n",
        "resumen = pd.merge(compras_por_segmento, monto_por_segmento, on='segmento')\n",
        "resumen_ordenado = resumen.sort_values(by='cantidad_compras', ascending=False)\n",
        "\n",
        "# Mostrar resultado\n",
        "print(\"\\nResumen por segmento:\")\n",
        "print(resumen_ordenado)\n",
        "\n",
        "# Exportar resultado\n",
        "resumen_ordenado.to_csv('/content/resumen_segmento.csv', index=False)\n",
        "print(\"\\nArchivo 'resumen_segmento.csv' exportado correctamente.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZWe0tzgHRB2I",
        "outputId": "6b9a1c3a-9255-4706-fef6-a39f26448565"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Usuarios:\n",
            "   user_id segmento registro_fecha\n",
            "0        1        A     2023-01-10\n",
            "1        2        B     2023-02-15\n",
            "2        3        A     2023-03-01\n",
            "3        4        C     2023-01-20\n",
            "4        5        B     2023-02-05\n",
            "\n",
            "Compras:\n",
            "   user_id  compra_id  monto\n",
            "0        1        101    200\n",
            "1        1        102    150\n",
            "2        2        103    300\n",
            "3        3        104    120\n",
            "4        3        105    180\n",
            "\n",
            "Merge realizado:\n",
            "   user_id segmento registro_fecha  compra_id  monto\n",
            "0        1        A     2023-01-10        101    200\n",
            "1        1        A     2023-01-10        102    150\n",
            "2        2        B     2023-02-15        103    300\n",
            "3        3        A     2023-03-01        104    120\n",
            "4        3        A     2023-03-01        105    180\n",
            "\n",
            "Resumen por segmento:\n",
            "  segmento  cantidad_compras  monto_total\n",
            "0        A                 5          750\n",
            "1        B                 2          550\n",
            "2        C                 1          500\n",
            "\n",
            "Archivo 'resumen_segmento.csv' exportado correctamente.\n"
          ]
        }
      ]
    }
  ]
}
